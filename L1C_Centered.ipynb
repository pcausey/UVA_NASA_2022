{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1C Centering on Latitude\n",
    "\n",
    "* Option for how many pixels from center it should grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs/gpfs0/project/sdscap-shakeri/nasa/UVA_NASA_2021'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "# from pyhdf.SD import SD, SDC\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "os.chdir('/project/sdscap-shakeri/nasa/UVA_NASA_2021')\n",
    "import icare\n",
    "import pickle\n",
    "import copy\n",
    "from netCDF4 import Dataset\n",
    "import netCDF4\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('C:\\\\Users\\\\whetz\\\\Documents\\\\UVA MSDS\\\\NASA\\\\hdf_files')\n",
    "# session = icare.ICARESession('/project/sdscap-shakeri/nasa/HDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path='PARASOL/L1_B-HDF.v1.00/2008/2008_06_01'\n",
    "# file_list = list(session.listdir(path))\n",
    "# file_path = path + '/' + file_list[0]\n",
    "# session.get_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/project/sdscap-shakeri/nasa/HDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"PARASOL/L1_B-HDF.v1.00/2008/2008_06_01/POLDER3_L1B-BG1-080146M_2008-06-01T00-08-19_V1-00.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = False\n",
    "pixels = 10\n",
    "x1 = 26\n",
    "x2 = x1+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3240, 6480, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i490 = f['Data_Directional_Fields']['I490P']\n",
    "i490_fill = i490.attrs['_FillValue']\n",
    "i490_arr = np.array(i490)\n",
    "\n",
    "print(i490_fill)\n",
    "i490_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20995200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3240*6480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut down extra lat/lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2718\n",
      "5187\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "cols = []\n",
    "for row in range(i490.shape[0]):\n",
    "    inds = np.where(np.abs(i490_arr[row]) != i490_fill)\n",
    "    if (len(inds[0])) > 0:\n",
    "        rows.append(row)\n",
    "        continue\n",
    "\n",
    "print(len(rows))\n",
    "\n",
    "for col in range(i490.shape[1]):\n",
    "    inds = np.where(np.abs(i490_arr[:,col]) != i490_fill)\n",
    "    if len(inds[0]) > 0:\n",
    "        cols.append(col)\n",
    "        continue\n",
    "                    \n",
    "print(len(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335923200\n",
      "225572256\n",
      "-0.3285005144032922\n"
     ]
    }
   ],
   "source": [
    "new_shape = (i490_arr[rows])[:,cols].shape\n",
    "shape = i490_arr.shape\n",
    "print(np.product(shape))\n",
    "print(np.product(new_shape))\n",
    "print((np.product(new_shape)-np.product(shape))/np.product(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0, ..., 2716, 2716, 2717]),\n",
       " array([2659, 2660, 2661, ..., 1743, 1744, 1743]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_arr = (i490_arr[rows])[:,cols]\n",
    "np.where(np.abs(new_arr) != i490_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3916, -32767, -32767, -32767, -32767, -32767, -32767, -32767,\n",
       "       -32767, -32767, -32767, -32767, -32767, -32767, -32767, -32767],\n",
       "      dtype=int16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_arr[0,2661]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lat/Long Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows (first dimension) have all the same lats, all different lons\n",
    "\n",
    "Cols (second dimension) have different lats, all different lons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angles, Altitude, & Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_scale = 1000\n",
    "new_scale = 1/reverse_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "final_dict['geolocation_data'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['Latitude', 'Longitude', 'column_number', 'land_sea_flag', 'row_number', 'surface_altitude']>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['Geolocation_Fields'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2719, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8157"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get latitude array and corresponding indices\n",
    "geo_inds = [[],[]]\n",
    "\n",
    "lats = np.array(f['Geolocation_Fields']['Latitude'])\n",
    "lons = np.array(f['Geolocation_Fields']['Longitude'])\n",
    "\n",
    "flag = True\n",
    "for i in range(lats.shape[0]):\n",
    "    inds = np.where(np.abs(lats[i]) != 99999)[0]\n",
    "\n",
    "    vals = lats[i][inds]\n",
    "\n",
    "    if len(np.unique(vals)) > 1:\n",
    "        print(\"Error\", i)\n",
    "        break\n",
    "    elif len(np.unique(vals)) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        val = np.unique(vals)[0]\n",
    "    \n",
    "    center_ind = int(np.sum(inds)/len(inds))\n",
    "\n",
    "    if center_ind < 1:\n",
    "        continue\n",
    "    else:\n",
    "        temp_lats = lats[i][center_ind-1:center_ind+2] \n",
    "        geo_inds[0].extend([i for u in range(3)])\n",
    "        geo_inds[1].extend([u for u in range(center_ind-1,center_ind+2)])\n",
    "        \n",
    "    if flag:\n",
    "        new_lats = np.array([temp_lats])\n",
    "        flag = False\n",
    "    else:\n",
    "        new_lats = np.append(new_lats, np.array([temp_lats]), axis=0)\n",
    "        \n",
    "geo_shape = (new_lats.shape)\n",
    "print(geo_shape)\n",
    "len(geo_inds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-14aaa9fcb905>:24: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  final_dict['geolocation_data'][tag]['data'] = np.round(temp_arr[geo_inds].reshape(geo_shape)).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude\n",
      "altitude\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-14aaa9fcb905>:27: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  final_dict['geolocation_data'][tag]['data'] = (np.array(f['Geolocation_Fields'][field]))[geo_inds].reshape(geo_shape)\n"
     ]
    }
   ],
   "source": [
    "for field in ['Latitude','Longitude','surface_altitude']:\n",
    "    if field == 'surface_altitude':\n",
    "        tag = 'altitude'\n",
    "    else:\n",
    "        tag = field.lower()\n",
    "    print(tag)\n",
    "\n",
    "        \n",
    "    final_dict['geolocation_data'][tag] = {}\n",
    "\n",
    "    final_dict['geolocation_data'][tag]['long_name'] = f['Geolocation_Fields'][field].attrs['long_name']\n",
    "    final_dict['geolocation_data'][tag]['units'] = f['Geolocation_Fields'][field].attrs['units']\n",
    "    \n",
    "    if tag in ['latitude','longitude']:\n",
    "        temp_arr = np.array(f['Geolocation_Fields'][field])\n",
    "        fill = f['Geolocation_Fields'][field].attrs['_FillValue']\n",
    "        fill_inds = np.where(temp_arr == fill)\n",
    "        temp_arr = temp_arr*reverse_scale\n",
    "        temp_arr[fill_inds] = fill\n",
    "        fill = int(fill)\n",
    "        \n",
    "        final_dict['geolocation_data'][tag]['fill'] = fill\n",
    "        final_dict['geolocation_data'][tag]['scale'] = new_scale\n",
    "        final_dict['geolocation_data'][tag]['data'] = np.round(temp_arr[geo_inds].reshape(geo_shape)).astype(int)\n",
    "    else:\n",
    "        final_dict['geolocation_data'][tag]['scale'] = f['Geolocation_Fields'][field].attrs['scale_factor']\n",
    "        final_dict['geolocation_data'][tag]['data'] = (np.array(f['Geolocation_Fields'][field]))[geo_inds].reshape(geo_shape)\n",
    "        final_dict['geolocation_data'][tag]['fill'] = f['Geolocation_Fields'][field].attrs['_FillValue']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-1d48cb3765a3>:19: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  final_dict['geolocation_data'][tag]['data'] = (np.array(f['Data_Directional_Fields'][field]))[geo_inds].reshape(field_shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solar_zenith (2719, 3, 16)\n",
      "sensor_zenith (2719, 3, 16)\n",
      "relative_azimuth (2719, 3, 16)\n"
     ]
    }
   ],
   "source": [
    "for field in ['thetas','thetav','phi']:\n",
    "    if field == 'thetas':\n",
    "        tag = 'solar_zenith'\n",
    "    elif field == 'thetav':\n",
    "        tag = 'sensor_zenith'\n",
    "    elif field == 'phi':\n",
    "        tag = 'relative_azimuth'\n",
    "        \n",
    "    # Define the shape of the data\n",
    "    field_shape = list(geo_shape)\n",
    "    field_shape.append(np.array(f['Data_Directional_Fields'][field]).shape[-1])\n",
    "    field_shape = tuple(field_shape)\n",
    "        \n",
    "    final_dict['geolocation_data'][tag] = {}\n",
    "    final_dict['geolocation_data'][tag]['scale'] = f['Data_Directional_Fields'][field].attrs['scale_factor']\n",
    "    final_dict['geolocation_data'][tag]['long_name'] = f['Data_Directional_Fields'][field].attrs['long_name']\n",
    "    final_dict['geolocation_data'][tag]['fill'] = f['Data_Directional_Fields'][field].attrs['_FillValue']\n",
    "    final_dict['geolocation_data'][tag]['units'] = f['Data_Directional_Fields'][field].attrs['units']\n",
    "    final_dict['geolocation_data'][tag]['data'] = (np.array(f['Data_Directional_Fields'][field]))[geo_inds].reshape(field_shape)\n",
    "    print(tag, final_dict['geolocation_data'][tag]['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate I, Q, & U fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_np\n",
      "tag: I\n",
      "I1020NP, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-8d4c14384ad1>:34: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  arrays.append(np.array(f['Data_Directional_Fields'][field])[geo_inds].reshape(field_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I443NP, I490P, I565NP, I670P, I763NP, I765NP, I865P, I910NP, (2719, 3, 16, 9)\n",
      "I_p\n",
      "tag: I\n",
      "I490P, I670P, I865P, (2719, 3, 16, 3)\n",
      "Q\n",
      "tag: Q\n",
      "Q490P, Q670P, Q865P, (2719, 3, 16, 3)\n",
      "U\n",
      "tag: U\n",
      "U490P, U670P, U865P, (2719, 3, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "measurement_dict = {}\n",
    "for cat in ['I_np','I_p','Q','U']:\n",
    "    print(cat)\n",
    "    \n",
    "    if cat == 'I_np':\n",
    "        tag = cat.replace('_np','')\n",
    "        fields = ([field for field in list(f['Data_Directional_Fields'].keys()) if (tag in field)])\n",
    "    else:\n",
    "        tag = cat.replace('_p','')\n",
    "        fields = ([field for field in list(f['Data_Directional_Fields'].keys()) if (tag in field) and ('NP' not in field)])\n",
    "\n",
    "    print(\"tag:\", tag)\n",
    "    fields.sort()\n",
    "    \n",
    "    # Define the shape of the data\n",
    "    field_shape = list(geo_shape)\n",
    "    field_shape.append(np.array(f['Data_Directional_Fields'][field]).shape[-1])\n",
    "    field_shape = tuple(field_shape)    \n",
    "    \n",
    "    arrays = []\n",
    "    scales = []\n",
    "    long_names = []\n",
    "    fills = []\n",
    "    units = []\n",
    "    for field in fields:\n",
    "            \n",
    "        print(field, end=\", \")\n",
    "        \n",
    "        scales.append(f['Data_Directional_Fields'][field].attrs['scale_factor'])\n",
    "        long_names.append(f['Data_Directional_Fields'][field].attrs['long_name'])\n",
    "        fills.append(f['Data_Directional_Fields'][field].attrs['_FillValue'])\n",
    "        units.append(f['Data_Directional_Fields'][field].attrs['units'])\n",
    "        \n",
    "        arrays.append(np.array(f['Data_Directional_Fields'][field])[geo_inds].reshape(field_shape))\n",
    "\n",
    "    if len(np.unique(scales)) == 1:\n",
    "        scales = scales[0]\n",
    "    if len(np.unique(fills)) == 1:\n",
    "        fills = fills[0]\n",
    "    if len(np.unique(units)) == 1:\n",
    "        units = units[0]\n",
    "    \n",
    "    measurement_dict[cat] = {}\n",
    "    measurement_dict[cat]['fields'] = fields\n",
    "    measurement_dict[cat]['scale'] = scales\n",
    "    measurement_dict[cat]['long_name'] = long_names\n",
    "    measurement_dict[cat]['fill'] = fills\n",
    "    measurement_dict[cat]['units'] = units\n",
    "    measurement_dict[cat]['data'] = np.stack(arrays,axis=3)\n",
    "    print(measurement_dict[cat]['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2719, 3, 16, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurement_dict['I_np']['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Final Dictionary and Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict['observation_data'] = {}\n",
    "final_dict['observation_data']['I_PARASOL'] = copy.deepcopy(measurement_dict['I_np'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarization_wavelengths\n",
      "(16, 3)\n",
      "\n",
      "intensity_wavelengths\n",
      "(16, 9)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_dict['sensor_views_bands'] = {}\n",
    "\n",
    "for i in [True, False]:\n",
    "    if i:\n",
    "        tag = 'I_p'\n",
    "        field_name = 'polarization_wavelengths'\n",
    "        lambdas = [int(field.replace('I','').replace('P','')) for field in measurement_dict[tag]['fields']]\n",
    "\n",
    "    else:\n",
    "        tag = 'I_np'\n",
    "        field_name = 'intensity_wavelengths'\n",
    "        lambdas = [int(field.replace('I','').replace('NP','').replace('P','')) for field in measurement_dict[tag]['fields']]\n",
    "\n",
    "\n",
    "    shape = measurement_dict[tag]['data'].shape\n",
    "    new_shape = []\n",
    "    lambda_arrs = []\n",
    "    \n",
    "    print(field_name)\n",
    "    \n",
    "    for lam in lambdas:  \n",
    "        lambda_arrs.append(np.full(16,lam))\n",
    "\n",
    "    full_lambdas_arr = np.stack(lambda_arrs,axis=1)\n",
    "    print(full_lambdas_arr.shape)\n",
    "\n",
    "    \n",
    "    final_dict['sensor_views_bands'][field_name] = {}\n",
    "    final_dict['sensor_views_bands'][field_name]['scale'] = 1\n",
    "    final_dict['sensor_views_bands'][field_name]['long_name'] = 'field_name'\n",
    "    final_dict['sensor_views_bands'][field_name]['fill'] = 32767\n",
    "    final_dict['sensor_views_bands'][field_name]['units'] = 'tbd'\n",
    "    final_dict['sensor_views_bands'][field_name]['data'] = full_lambdas_arr\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOLP\n",
    "* Calculate DOLP matrix\n",
    "    * DOLP = sqrt(Q^2 + U^2)/I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32767"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = measurement_dict['Q']['scale']\n",
    "scale\n",
    "fill = measurement_dict['Q']['fill']\n",
    "fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale, abs\n",
    "for key in measurement_dict.keys():\n",
    "    if key == 'I_p':\n",
    "        I_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        I_arr[np.abs(I_arr) == fill] = 1\n",
    "    \n",
    "    elif key == 'Q':\n",
    "        Q_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        Q_arr[np.abs(Q_arr) == fill] = 1\n",
    "        \n",
    "    elif key == 'U':\n",
    "        U_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        U_arr[np.abs(U_arr) == fill] = 1\n",
    "        \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-bca893dafdb9>:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  DOLP_arr_unfltrd = np.divide(np.sqrt(np.add(np.square(Q_arr), np.square(U_arr))), I_arr)*reverse_scale\n"
     ]
    }
   ],
   "source": [
    "DOLP_arr_unfltrd = np.divide(np.sqrt(np.add(np.square(Q_arr), np.square(U_arr))), I_arr)*reverse_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename - DOLP\n",
    "DOLP_arr_unfltrd[np.where((measurement_dict['I_p']['data'] == fill) | \n",
    "                          (measurement_dict['Q']['data'] == fill) | \n",
    "                          (measurement_dict['U']['data'] == fill))] = fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = np.where((np.abs(I_arr) != (fill * scale)) & (np.abs(Q_arr) != (fill * scale)) & (np.abs(U_arr) != (fill * scale)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to dictionary\n",
    "\n",
    "final_dict['observation_data']['DOLP_PARASOL'] = {}\n",
    "# measurement_dict[cat]['fields'] = fields\n",
    "final_dict['observation_data']['DOLP_PARASOL']['scale'] = new_scale\n",
    "final_dict['observation_data']['DOLP_PARASOL']['long_name'] = 'Degree of linear polarization'\n",
    "final_dict['observation_data']['DOLP_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['DOLP_PARASOL']['units'] = 'None'\n",
    "final_dict['observation_data']['DOLP_PARASOL']['data'] = np.round(DOLP_arr_unfltrd).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q over I, U over I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Q over I\n",
      "Processing U over I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-63afa7411eca>:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  Q_over_I = np.divide(Q_arr, I_arr)*reverse_scale\n",
      "<ipython-input-29-63afa7411eca>:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  U_over_I = np.divide(U_arr, I_arr)*reverse_scale\n"
     ]
    }
   ],
   "source": [
    "Q_over_I = np.divide(Q_arr, I_arr)*reverse_scale\n",
    "U_over_I = np.divide(U_arr, I_arr)*reverse_scale\n",
    "\n",
    "Q_over_I[np.where((measurement_dict['I_p']['data'] == fill) | \n",
    "                          (measurement_dict['Q']['data'] == fill) | \n",
    "                          (measurement_dict['U']['data'] == fill))] = fill\n",
    "\n",
    "U_over_I[np.where((measurement_dict['I_p']['data'] == fill) | \n",
    "                          (measurement_dict['Q']['data'] == fill) | \n",
    "                          (measurement_dict['U']['data'] == fill))] = fill\n",
    "\n",
    "print(\"Processing Q over I\")\n",
    "final_dict['observation_data']['Q_over_I_PARASOL'] = {}\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['scale'] = new_scale\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['long_name'] = 'Q over I'\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['units'] = 'None'\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['data'] = np.round(Q_over_I).astype(int)\n",
    "\n",
    "print(\"Processing U over I\")\n",
    "final_dict['observation_data']['U_over_I_PARASOL'] = {}\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['scale'] = new_scale\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['long_name'] = 'U over I'\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['units'] = 'None'\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['data'] = np.round(U_over_I).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geolocation_data latitude int64\n",
      "geolocation_data longitude int64\n",
      "geolocation_data altitude int16\n",
      "geolocation_data solar_zenith uint16\n",
      "geolocation_data sensor_zenith uint16\n",
      "geolocation_data relative_azimuth uint16\n",
      "observation_data I_PARASOL int16\n",
      "observation_data DOLP_PARASOL int64\n",
      "observation_data Q_over_I_PARASOL int64\n",
      "observation_data U_over_I_PARASOL int64\n",
      "sensor_views_bands polarization_wavelengths int64\n",
      "sensor_views_bands intensity_wavelengths int64\n"
     ]
    }
   ],
   "source": [
    "for cat in final_dict.keys():\n",
    "    for variable in final_dict[cat]:\n",
    "        print(cat, variable, (final_dict[cat][variable]['data']).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nc(variable_dict, filename):\n",
    "    \n",
    "    nc = Dataset(filename, mode='w', format='NETCDF4')\n",
    "\n",
    "    for cat in variable_dict.keys():\n",
    "        print(\"Starting:\", cat)\n",
    "        \n",
    "        # Create the category group to store the variables\n",
    "        nc.createGroup(cat)\n",
    "\n",
    "        for var in variable_dict[cat].keys():\n",
    "            print(var)\n",
    "\n",
    "            shape = final_dict[cat][var]['data'].shape\n",
    "            \n",
    "            # Fill the dimension with variables\n",
    "            dimensions = []\n",
    "            for i in range(len(shape)):  \n",
    "                dim_name = f'{var}_{i}'\n",
    "                nc.createDimension(dim_name, size=shape[i])\n",
    "                dimensions.append(dim_name)\n",
    "\n",
    "            # Create the variable instance\n",
    "            print('creating variable')\n",
    "            nc[cat].createVariable(var, datatype='i8', dimensions=dimensions, fill_value=variable_dict[cat][var]['fill'])\n",
    "\n",
    "            # Create variable metadata\n",
    "            print('creating the metadataverse')\n",
    "            nc[cat][var].long_name = variable_dict[cat][var]['long_name']\n",
    "            nc[cat][var].units = variable_dict[cat][var]['units']\n",
    "            nc[cat][var].scale_factor = variable_dict[cat][var]['scale']\n",
    "\n",
    "            # Create variable array \n",
    "            print('creating variable array')\n",
    "            nc[cat][var][:] = variable_dict[cat][var]['data']\n",
    "            \n",
    "            print(\"\")\n",
    "            \n",
    "    nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/gpfs/gpfs0/project/sdscap-shakeri/nasa/UVA_NASA_2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: geolocation_data\n",
      "latitude\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "longitude\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "altitude\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "solar_zenith\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "sensor_zenith\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "relative_azimuth\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "Starting: observation_data\n",
      "I_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "DOLP_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "Q_over_I_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "U_over_I_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "Starting: sensor_views_bands\n",
      "polarization_wavelengths\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "intensity_wavelengths\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_nc(final_dict, 'example_centered.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = Dataset('example_centered.nc', mode='r', format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0, ..., 2718, 2718, 2718]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([ 0,  0,  0, ..., 15, 15, 15]),\n",
       " array([0, 1, 2, ..., 6, 7, 8]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.array(nc.groups['observation_data']['I_PARASOL'])\n",
    "np.where(i != 32767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -99999.,  109125.,  111375.],\n",
       "       [ 100843.,  103012.,  105181.],\n",
       "       [  97326.,   99419.,  101512.],\n",
       "       ...,\n",
       "       [-156992., -156873., -156753.],\n",
       "       [-157066., -156946., -156826.],\n",
       "       [ -99999., -157140.,  -99999.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(nc.groups['geolocation_data']['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0, ..., 2717, 2717, 2718]),\n",
       " array([1, 1, 2, ..., 1, 2, 1]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " array([3, 4, 3, ..., 2, 2, 2]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_PARASOL = final_dict['observation_data']['I_PARASOL']['data']\n",
    "np.where(np.abs(I_PARASOL) != 32767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
