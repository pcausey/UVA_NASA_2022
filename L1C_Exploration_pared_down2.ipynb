{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1C Formatting Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs/gpfs0/project/sdscap-shakeri/nasa/UVA_NASA_2021'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "# from pyhdf.SD import SD, SDC\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "os.chdir('/project/sdscap-shakeri/nasa/UVA_NASA_2021')\n",
    "import icare\n",
    "import pickle\n",
    "import copy\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ICARE Username: sjw5ke@virginia.edu\n",
      "ICARE Password: ···········\n"
     ]
    }
   ],
   "source": [
    "# os.chdir('C:\\\\Users\\\\whetz\\\\Documents\\\\UVA MSDS\\\\NASA\\\\hdf_files')\n",
    "session = icare.ICARESession('/project/sdscap-shakeri/nasa/HDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/project/sdscap-shakeri/nasa/HDF/PARASOL/L1_B-HDF.v1.00/2008/2008_06_01/POLDER3_L1B-BG1-080146M_2008-06-01T00-08-19_V1-00.h5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='PARASOL/L1_B-HDF.v1.00/2008/2008_06_01'\n",
    "file_list = list(session.listdir(path))\n",
    "file_path = path + '/' + file_list[0]\n",
    "session.get_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/project/sdscap-shakeri/nasa/HDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"PARASOL/L1_B-HDF.v1.00/2008/2008_06_01/POLDER3_L1B-BG1-080146M_2008-06-01T00-08-19_V1-00.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create example file from h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_np\n",
      "tag: I\n",
      "['I1020NP', 'I443NP', 'I490P', 'I565NP', 'I670P', 'I763NP', 'I765NP', 'I865P', 'I910NP']\n",
      "I1020NP, I443NP, I490P, I565NP, I670P, I763NP, I765NP, I865P, I910NP, I_p\n",
      "tag: I\n",
      "['I490P', 'I670P', 'I865P']\n",
      "I490P, I670P, I865P, Q\n",
      "tag: Q\n",
      "['Q490P', 'Q670P', 'Q865P']\n",
      "Q490P, Q670P, Q865P, U\n",
      "tag: U\n",
      "['U490P', 'U670P', 'U865P']\n",
      "U490P, U670P, U865P, "
     ]
    }
   ],
   "source": [
    "measurement_dict = {}\n",
    "for cat in ['I_np','I_p','Q','U']:\n",
    "    print(cat)\n",
    "    \n",
    "    if cat == 'I_np':\n",
    "        tag = cat.replace('_np','')\n",
    "        fields = ([field for field in list(f['Data_Directional_Fields'].keys()) if (tag in field)])\n",
    "    else:\n",
    "        tag = cat.replace('_p','')\n",
    "        fields = ([field for field in list(f['Data_Directional_Fields'].keys()) if (tag in field) and ('NP' not in field)])\n",
    "\n",
    "    print(\"tag:\", tag)\n",
    "    fields.sort()\n",
    "    print(fields)\n",
    "    arrays = []\n",
    "    scales = []\n",
    "    long_names = []\n",
    "    fills = []\n",
    "    units = []\n",
    "    for field in fields:\n",
    "            \n",
    "        print(field, end=\", \")\n",
    "        \n",
    "        scales.append(f['Data_Directional_Fields'][field].attrs['scale_factor'])\n",
    "        long_names.append(f['Data_Directional_Fields'][field].attrs['long_name'])\n",
    "        fills.append(f['Data_Directional_Fields'][field].attrs['_FillValue'])\n",
    "        units.append(f['Data_Directional_Fields'][field].attrs['units'])\n",
    "\n",
    "        arrays.append(np.array(f['Data_Directional_Fields'][field])[0][0])\n",
    "        \n",
    "    if len(np.unique(scales)) == 1:\n",
    "        scales = scales[0]\n",
    "    if len(np.unique(fills)) == 1:\n",
    "        fills = fills[0]\n",
    "    if len(np.unique(units)) == 1:\n",
    "        units = units[0]\n",
    "    \n",
    "    measurement_dict[cat] = {}\n",
    "    measurement_dict[cat]['fields'] = fields\n",
    "    measurement_dict[cat]['scale'] = scales\n",
    "    measurement_dict[cat]['long_name'] = long_names\n",
    "    measurement_dict[cat]['fill'] = fills\n",
    "    measurement_dict[cat]['units'] = units\n",
    "    measurement_dict[cat]['data'] = np.stack(arrays,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Final Dictionary and Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "final_dict['observation_data'] = {}\n",
    "final_dict['observation_data']['I_PARASOL'] = copy.deepcopy(measurement_dict['I_np'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarized\n",
      "(16, 3)\n",
      "non-polarized\n",
      "(16, 9)\n"
     ]
    }
   ],
   "source": [
    "def add_wavelengths(polarized=True):\n",
    "    if polarized:\n",
    "        print(\"polarized\")\n",
    "        tag = 'I_p'\n",
    "        field_name = 'polarization_wavelengths'\n",
    "        lambdas = [int(field.replace('I','').replace('P','')) for field in measurement_dict[tag]['fields']]\n",
    "\n",
    "    else:\n",
    "        print(\"non-polarized\")\n",
    "        tag = 'I_np'\n",
    "        field_name = 'intensity_wavelengths'\n",
    "        lambdas = [int(field.replace('I','').replace('NP','').replace('P','')) for field in measurement_dict[tag]['fields']]\n",
    "\n",
    "    shape = measurement_dict[tag]['data'].shape\n",
    "    new_shape = []\n",
    "\n",
    "    lambda_arrs = []\n",
    "\n",
    "    for lam in lambdas:    \n",
    "        new_shape = []\n",
    "        for dim in shape[:-1]:\n",
    "            new_shape.append(dim)\n",
    "        # new_shape.append(1)\n",
    "\n",
    "        lambda_arrs.append(np.full(new_shape, fill_value = np.full(16,lam)))\n",
    "        # break\n",
    "\n",
    "    full_lambdas_arr = np.stack(lambda_arrs,axis=1)\n",
    "    print(full_lambdas_arr.shape)\n",
    "    \n",
    "    final_dict['sensor_views_bands'] = {}\n",
    "    final_dict['sensor_views_bands'][field_name] = {}\n",
    "    final_dict['sensor_views_bands'][field_name]['scale'] = 1\n",
    "    final_dict['sensor_views_bands'][field_name]['long_name'] = 'field_name'\n",
    "    final_dict['sensor_views_bands'][field_name]['fill'] = 32767\n",
    "    final_dict['sensor_views_bands'][field_name]['units'] = 'tbd'\n",
    "    final_dict['sensor_views_bands'][field_name]['data'] = full_lambdas_arr\n",
    "    \n",
    "for i in [True,False]:\n",
    "    add_wavelengths(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['I_np', 'I_p', 'Q', 'U'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurement_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOLP\n",
    "* Calculate DOLP matrix\n",
    "    * DOLP = sqrt(Q^2 + U^2)/I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32767"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = measurement_dict['Q']['scale']\n",
    "scale\n",
    "fill = measurement_dict['Q']['fill']\n",
    "fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale, abs\n",
    "for key in measurement_dict.keys():\n",
    "    if key == 'I_p':\n",
    "        I_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        I_arr[np.abs(I_arr) == fill] = 1\n",
    "    \n",
    "    elif key == 'Q':\n",
    "        Q_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        Q_arr[np.abs(Q_arr) == fill] = 1\n",
    "        \n",
    "    elif key == 'U':\n",
    "        U_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        U_arr[np.abs(U_arr) == fill] = 1\n",
    "        \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOLP_arr_unfltrd = np.divide(np.sqrt(np.add(np.square(Q_arr), np.square(U_arr))), I_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename - DOLP\n",
    "DOLP_arr_unfltrd[np.where((measurement_dict['I_p']['data'] == fill) | \n",
    "                          (measurement_dict['Q']['data'] == fill) | \n",
    "                          (measurement_dict['U']['data'] == fill))] = fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = np.where((np.abs(I_arr) != (fill * scale)) & (np.abs(Q_arr) != (fill * scale)) & (np.abs(U_arr) != (fill * scale)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to dictionary\n",
    "\n",
    "final_dict['observation_data']['DOLP_PARASOL'] = {}\n",
    "# measurement_dict[cat]['fields'] = fields\n",
    "final_dict['observation_data']['DOLP_PARASOL']['scale'] = 1\n",
    "final_dict['observation_data']['DOLP_PARASOL']['long_name'] = 'INSERT LONG NAME'\n",
    "final_dict['observation_data']['DOLP_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['DOLP_PARASOL']['units'] = 'INSERT UNITS'\n",
    "final_dict['observation_data']['DOLP_PARASOL']['data'] = DOLP_arr_unfltrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q over I, U over I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q_over_I = np.divide(Q_arr, I_arr)\n",
    "U_over_I = np.divide(U_arr, I_arr)\n",
    "\n",
    "Q_over_I[np.where((measurement_dict['I_p']['data'] == fill) | \n",
    "                          (measurement_dict['Q']['data'] == fill) | \n",
    "                          (measurement_dict['U']['data'] == fill))] = fill\n",
    "\n",
    "U_over_I[np.where((measurement_dict['I_p']['data'] == fill) | \n",
    "                          (measurement_dict['Q']['data'] == fill) | \n",
    "                          (measurement_dict['U']['data'] == fill))] = fill\n",
    "\n",
    "final_dict['observation_data']['Q_over_I_PARASOL'] = {}\n",
    "# measurement_dict[cat]['fields'] = fields\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['scale'] = 1\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['long_name'] = 'INSERT LONG NAME'\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['units'] = 'INSERT UNITS'\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['data'] = Q_over_I\n",
    "\n",
    "final_dict['observation_data']['U_over_I_PARASOL'] = {}\n",
    "# measurement_dict[cat]['fields'] = fields\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['scale'] = 1\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['long_name'] = 'INSERT LONG NAME'\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['units'] = 'INSERT UNITS'\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['data'] = U_over_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import netCDF4\n",
    "\n",
    "def write_nc(variable_dict, filename):\n",
    "\n",
    "    try:\n",
    "        nc.close()\n",
    "    \n",
    "    except:\n",
    "        print('opening new file')\n",
    "    \n",
    "    nc = Dataset(filename, mode='w', format='NETCDF4')\n",
    "\n",
    "    for cat in variable_dict.keys():\n",
    "\n",
    "        # Create the category group to store the variables\n",
    "        nc.createGroup(cat)\n",
    "\n",
    "        for var in variable_dict[cat].keys():\n",
    "            print(var)\n",
    "\n",
    "            # Fill the dimension with variables\n",
    "            dimensions = []\n",
    "            for i in range(len(variable_dict[cat][var]['data'].shape)):  \n",
    "                dim_name = f'{var}_{i}'\n",
    "                nc.createDimension(dim_name, size=None)\n",
    "                dimensions.append(dim_name)\n",
    "\n",
    "            # Create the variable instance\n",
    "            print('creating variable')\n",
    "            nc[cat].createVariable(var, datatype='f4', dimensions=dimensions, fill_value=variable_dict[cat][var]['fill'])\n",
    "\n",
    "            # Create variable metadata\n",
    "            print('creating the metaverse')\n",
    "            nc[cat][var].long_name = variable_dict[cat][var]['long_name']\n",
    "            nc[cat][var].units = variable_dict[cat][var]['units']\n",
    "            nc[cat][var].scale_factor = variable_dict[cat][var]['scale']\n",
    "\n",
    "            # Create variable array \n",
    "            print('create variable array')\n",
    "            nc[cat][var][:] = variable_dict[cat][var]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/gpfs/gpfs0/project/sdscap-shakeri/nasa/UVA_NASA_2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening new file\n",
      "I_PARASOL\n",
      "creating variable\n",
      "creating the metaverse\n",
      "create variable array\n",
      "DOLP_PARASOL\n",
      "creating variable\n",
      "creating the metaverse\n",
      "create variable array\n",
      "Q_over_I_PARASOL\n",
      "creating variable\n",
      "creating the metaverse\n",
      "create variable array\n",
      "U_over_I_PARASOL\n",
      "creating variable\n",
      "creating the metaverse\n",
      "create variable array\n",
      "intensity_wavelengths\n",
      "creating variable\n",
      "creating the metaverse\n",
      "create variable array\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4 data model, file format HDF5):\n",
       "    dimensions(sizes): I_PARASOL_0(16), I_PARASOL_1(9), DOLP_PARASOL_0(16), DOLP_PARASOL_1(3), Q_over_I_PARASOL_0(16), Q_over_I_PARASOL_1(3), U_over_I_PARASOL_0(16), U_over_I_PARASOL_1(3), intensity_wavelengths_0(16), intensity_wavelengths_1(9)\n",
       "    variables(dimensions): \n",
       "    groups: observation_data, sensor_views_bands"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_nc(final_dict, 'example_single_pixel.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: netCDF4 in /sfs/qumulo/qhome/sjw5ke/.local/lib/python3.8/site-packages (1.5.8)\n",
      "Requirement already satisfied: numpy>=1.9 in /sfs/applications/202112/software/standard/compiler/gcc/9.2.0/jupyter_conda/2020.11-py3.8/lib/python3.8/site-packages (from netCDF4) (1.19.2)\n",
      "Requirement already satisfied: cftime in /sfs/qumulo/qhome/sjw5ke/.local/lib/python3.8/site-packages (from netCDF4) (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = Dataset(\"example_single_pixel.nc\", \"r\", format=\"NETCDF4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.],\n",
       "       [32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
       "        32767.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(nc.groups['observation_data']['I_PARASOL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
