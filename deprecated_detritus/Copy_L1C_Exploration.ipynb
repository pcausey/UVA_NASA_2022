{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1C Formatting Eploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs/gpfs0/project/sdscap-shakeri/nasa/UVA_NASA_2021'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "# from pyhdf.SD import SD, SDC\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "os.chdir('/project/sdscap-shakeri/nasa/UVA_NASA_2021')\n",
    "import icare\n",
    "import pickle\n",
    "import copy\n",
    "from netCDF4 import Dataset\n",
    "import netCDF4\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('C:\\\\Users\\\\whetz\\\\Documents\\\\UVA MSDS\\\\NASA\\\\hdf_files')\n",
    "# session = icare.ICARESession('/project/sdscap-shakeri/nasa/HDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path='PARASOL/L1_B-HDF.v1.00/2008/2008_06_01'\n",
    "# file_list = list(session.listdir(path))\n",
    "# file_path = path + '/' + file_list[0]\n",
    "# session.get_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/project/sdscap-shakeri/nasa/HDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"PARASOL/L1_B-HDF.v1.00/2008/2008_06_01/POLDER3_L1B-BG1-080146M_2008-06-01T00-08-19_V1-00.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create example file from h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_np\n",
      "tag: I\n",
      "['I1020NP', 'I443NP', 'I490P', 'I565NP', 'I670P', 'I763NP', 'I765NP', 'I865P', 'I910NP']\n",
      "I1020NP, I443NP, I490P, I565NP, I670P, I763NP, I765NP, I865P, I910NP, I_p\n",
      "tag: I\n",
      "['I490P', 'I670P', 'I865P']\n",
      "I490P, I670P, I865P, Q\n",
      "tag: Q\n",
      "['Q490P', 'Q670P', 'Q865P']\n",
      "Q490P, Q670P, Q865P, U\n",
      "tag: U\n",
      "['U490P', 'U670P', 'U865P']\n",
      "U490P, U670P, U865P, "
     ]
    }
   ],
   "source": [
    "measurement_dict = {}\n",
    "for cat in ['I_np','I_p','Q','U']:\n",
    "    print(cat)\n",
    "    \n",
    "    if cat == 'I_np':\n",
    "        tag = cat.replace('_np','')\n",
    "        fields = ([field for field in list(f['Data_Directional_Fields'].keys()) if (tag in field)])\n",
    "    else:\n",
    "        tag = cat.replace('_p','')\n",
    "        fields = ([field for field in list(f['Data_Directional_Fields'].keys()) if (tag in field) and ('NP' not in field)])\n",
    "\n",
    "    print(\"tag:\", tag)\n",
    "    fields.sort()\n",
    "    print(fields)\n",
    "    arrays = []\n",
    "    scales = []\n",
    "    long_names = []\n",
    "    fills = []\n",
    "    units = []\n",
    "    for field in fields:\n",
    "            \n",
    "        print(field, end=\", \")\n",
    "        \n",
    "        scales.append(f['Data_Directional_Fields'][field].attrs['scale_factor'])\n",
    "        long_names.append(f['Data_Directional_Fields'][field].attrs['long_name'])\n",
    "        fills.append(f['Data_Directional_Fields'][field].attrs['_FillValue'])\n",
    "        units.append(f['Data_Directional_Fields'][field].attrs['units'])\n",
    "\n",
    "        arrays.append(np.array(f['Data_Directional_Fields'][field]))\n",
    "        \n",
    "    if len(np.unique(scales)) == 1:\n",
    "        scales = scales[0]\n",
    "    if len(np.unique(fills)) == 1:\n",
    "        fills = fills[0]\n",
    "    if len(np.unique(units)) == 1:\n",
    "        units = units[0]\n",
    "    \n",
    "    measurement_dict[cat] = {}\n",
    "    measurement_dict[cat]['fields'] = fields\n",
    "    measurement_dict[cat]['scale'] = scales\n",
    "    measurement_dict[cat]['long_name'] = long_names\n",
    "    measurement_dict[cat]['fill'] = fills\n",
    "    measurement_dict[cat]['units'] = units\n",
    "    measurement_dict[cat]['data'] = np.stack(arrays,axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Final Dictionary and Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "final_dict['observation_data'] = {}\n",
    "final_dict['observation_data']['I_PARASOL'] = copy.deepcopy(measurement_dict['I_np'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarized\n",
      "(3240, 6480, 16, 3)\n",
      "non-polarized\n",
      "(3240, 6480, 16, 9)\n"
     ]
    }
   ],
   "source": [
    "for i in [True, False]:\n",
    "    if i:\n",
    "        print(\"polarized\")\n",
    "        tag = 'I_p'\n",
    "        field_name = 'polarization_wavelengths'\n",
    "        lambdas = [int(field.replace('I','').replace('P','')) for field in measurement_dict[tag]['fields']]\n",
    "\n",
    "    else:\n",
    "        print(\"non-polarized\")\n",
    "        tag = 'I_np'\n",
    "        field_name = 'intensity_wavelengths'\n",
    "        lambdas = [int(field.replace('I','').replace('NP','').replace('P','')) for field in measurement_dict[tag]['fields']]\n",
    "\n",
    "    shape = measurement_dict[tag]['data'].shape\n",
    "    new_shape = []\n",
    "\n",
    "    lambda_arrs = []\n",
    "\n",
    "    for lam in lambdas:    \n",
    "        new_shape = []\n",
    "        for dim in shape[:-1]:\n",
    "            new_shape.append(dim)\n",
    "        # new_shape.append(1)\n",
    "\n",
    "        lambda_arrs.append(np.full(new_shape, fill_value = np.full(16,lam)))\n",
    "        # break\n",
    "\n",
    "    full_lambdas_arr = np.stack(lambda_arrs,axis=3)\n",
    "    print(full_lambdas_arr.shape)\n",
    "    \n",
    "    final_dict['sensor_views_bands'] = {}\n",
    "    final_dict['sensor_views_bands'][field_name] = {}\n",
    "    final_dict['sensor_views_bands'][field_name]['scale'] = 1\n",
    "    final_dict['sensor_views_bands'][field_name]['long_name'] = 'field_name'\n",
    "    final_dict['sensor_views_bands'][field_name]['fill'] = 32767\n",
    "    final_dict['sensor_views_bands'][field_name]['units'] = 'tbd'\n",
    "    final_dict['sensor_views_bands'][field_name]['data'] = full_lambdas_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['I_np', 'I_p', 'Q', 'U'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurement_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOLP\n",
    "* Calculate DOLP matrix\n",
    "    * DOLP = sqrt(Q^2 + U^2)/I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_scale = 1000\n",
    "new_scale = 1/reverse_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32767"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = measurement_dict['Q']['scale']\n",
    "scale\n",
    "fill = measurement_dict['Q']['fill']\n",
    "fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale, abs\n",
    "for key in measurement_dict.keys():\n",
    "    if key == 'I_p':\n",
    "        I_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        I_arr[np.abs(I_arr) == fill] = 1\n",
    "    \n",
    "    elif key == 'Q':\n",
    "        Q_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        Q_arr[np.abs(Q_arr) == fill] = 1\n",
    "        \n",
    "    elif key == 'U':\n",
    "        U_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        U_arr[np.abs(U_arr) == fill] = 1\n",
    "        \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-bca893dafdb9>:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  DOLP_arr_unfltrd = np.divide(np.sqrt(np.add(np.square(Q_arr), np.square(U_arr))), I_arr)*reverse_scale\n"
     ]
    }
   ],
   "source": [
    "DOLP_arr_unfltrd = np.divide(np.sqrt(np.add(np.square(Q_arr), np.square(U_arr))), I_arr)*reverse_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename - DOLP\n",
    "DOLP_arr_unfltrd[np.where((measurement_dict['I_p']['data'] == fill) | \n",
    "                          (measurement_dict['Q']['data'] == fill) | \n",
    "                          (measurement_dict['U']['data'] == fill))] = fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = np.where((np.abs(I_arr) != (fill * scale)) & (np.abs(Q_arr) != (fill * scale)) & (np.abs(U_arr) != (fill * scale)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to dictionary\n",
    "\n",
    "final_dict['observation_data']['DOLP_PARASOL'] = {}\n",
    "# measurement_dict[cat]['fields'] = fields\n",
    "final_dict['observation_data']['DOLP_PARASOL']['scale'] = new_scale\n",
    "final_dict['observation_data']['DOLP_PARASOL']['long_name'] = 'Degree of linear polarization'\n",
    "final_dict['observation_data']['DOLP_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['DOLP_PARASOL']['units'] = 'None'\n",
    "final_dict['observation_data']['DOLP_PARASOL']['data'] = np.round(DOLP_arr_unfltrd).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q over I, U over I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-6b485eb901d3>:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  Q_over_I = np.divide(Q_arr, I_arr)*reverse_scale\n",
      "<ipython-input-19-6b485eb901d3>:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Q_over_I = np.divide(Q_arr, I_arr)*reverse_scale\n",
      "<ipython-input-19-6b485eb901d3>:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  U_over_I = np.divide(U_arr, I_arr)*reverse_scale\n",
      "<ipython-input-19-6b485eb901d3>:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  U_over_I = np.divide(U_arr, I_arr)*reverse_scale\n"
     ]
    }
   ],
   "source": [
    "Q_over_I = np.divide(Q_arr, I_arr)*reverse_scale\n",
    "U_over_I = np.divide(U_arr, I_arr)*reverse_scale\n",
    "\n",
    "Q_over_I[np.where((measurement_dict['I_p']['data'] == fill) | \n",
    "                          (measurement_dict['Q']['data'] == fill) | \n",
    "                          (measurement_dict['U']['data'] == fill))] = fill\n",
    "\n",
    "U_over_I[np.where((measurement_dict['I_p']['data'] == fill) | \n",
    "                          (measurement_dict['Q']['data'] == fill) | \n",
    "                          (measurement_dict['U']['data'] == fill))] = fill\n",
    "\n",
    "final_dict['observation_data']['Q_over_I_PARASOL'] = {}\n",
    "# measurement_dict[cat]['fields'] = fields\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['scale'] = new_scale\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['long_name'] = 'Q over I'\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['units'] = 'None'\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['data'] = np.round(Q_over_I).astype(int)\n",
    "\n",
    "final_dict['observation_data']['U_over_I_PARASOL'] = {}\n",
    "# measurement_dict[cat]['fields'] = fields\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['scale'] = new_scale\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['long_name'] = 'U over I'\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['units'] = 'None'\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['data'] = np.round(U_over_I).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angles, Altitude, & Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict['geolocation_data'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['Latitude', 'Longitude', 'column_number', 'land_sea_flag', 'row_number', 'surface_altitude']>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['Geolocation_Fields'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in ['thetas','thetav','phi']:\n",
    "    if field == 'thetas':\n",
    "        tag = 'solar_zenith'\n",
    "    elif field == 'thetav':\n",
    "        tag = 'sensor_zenith'\n",
    "    elif field == 'phi':\n",
    "        tag = 'relative_azimuth'\n",
    "        \n",
    "    final_dict['geolocation_data'][tag] = {}\n",
    "    final_dict['geolocation_data'][tag]['scale'] = f['Data_Directional_Fields'][field].attrs['scale_factor']\n",
    "    final_dict['geolocation_data'][tag]['long_name'] = f['Data_Directional_Fields'][field].attrs['long_name']\n",
    "    final_dict['geolocation_data'][tag]['fill'] = f['Data_Directional_Fields'][field].attrs['_FillValue']\n",
    "    final_dict['geolocation_data'][tag]['units'] = f['Data_Directional_Fields'][field].attrs['units']\n",
    "    final_dict['geolocation_data'][tag]['data'] = np.array(f['Data_Directional_Fields'][field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in ['Latitude','Longitude','surface_altitude']:\n",
    "    if field == 'surface_altitude':\n",
    "        tag = 'altitude'\n",
    "    else:\n",
    "        tag = field\n",
    "        \n",
    "        \n",
    "    final_dict['geolocation_data'][tag] = {}\n",
    "\n",
    "    final_dict['geolocation_data'][tag]['long_name'] = f['Geolocation_Fields'][field].attrs['long_name']\n",
    "    final_dict['geolocation_data'][tag]['units'] = f['Geolocation_Fields'][field].attrs['units']\n",
    "    \n",
    "    if tag in ['Latitude','Longitude']:\n",
    "        temp_arr = np.array(f['Geolocation_Fields'][field])\n",
    "        fill = f['Geolocation_Fields'][field].attrs['_FillValue']\n",
    "        fill_inds = np.where(temp_arr == fill)\n",
    "        temp_arr = temp_arr*reverse_scale\n",
    "        temp_arr[fill_inds] = fill\n",
    "        fill = int(fill)\n",
    "        \n",
    "        final_dict['geolocation_data'][tag]['fill'] = fill\n",
    "        final_dict['geolocation_data'][tag]['scale'] = new_scale\n",
    "        final_dict['geolocation_data'][tag]['data'] = np.round(temp_arr).astype(int)\n",
    "    else:\n",
    "        final_dict['geolocation_data'][tag]['scale'] = f['Geolocation_Fields'][field].attrs['scale_factor']\n",
    "        final_dict['geolocation_data'][tag]['data'] = np.array(f['Geolocation_Fields'][field])\n",
    "        final_dict['geolocation_data'][tag]['fill'] = f['Geolocation_Fields'][field].attrs['_FillValue']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_data I_PARASOL int16\n",
      "observation_data DOLP_PARASOL int64\n",
      "observation_data Q_over_I_PARASOL int64\n",
      "observation_data U_over_I_PARASOL int64\n",
      "sensor_views_bands intensity_wavelengths int64\n",
      "geolocation_data solar_zenith uint16\n",
      "geolocation_data sensor_zenith uint16\n",
      "geolocation_data relative_azimuth uint16\n",
      "geolocation_data Latitude int64\n",
      "geolocation_data Longitude int64\n",
      "geolocation_data altitude int16\n"
     ]
    }
   ],
   "source": [
    "for cat in final_dict.keys():\n",
    "    for variable in final_dict[cat]:\n",
    "        print(cat, variable, (final_dict[cat][variable]['data']).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def write_nc(variable_dict, filename):\n",
    "    \n",
    "    nc = Dataset(filename, mode='w', format='NETCDF4')\n",
    "\n",
    "    for cat in variable_dict.keys():\n",
    "        print(\"Starting:\", cat)\n",
    "        # Create the category group to store the variables\n",
    "        nc.createGroup(cat)\n",
    "\n",
    "        for var in variable_dict[cat].keys():\n",
    "            print(var)\n",
    "\n",
    "            # Fill the dimension with variables\n",
    "            dimensions = []\n",
    "            for i in range(len(variable_dict[cat][var]['data'].shape)):  \n",
    "                dim_name = f'{var}_{i}'\n",
    "                nc.createDimension(dim_name, size=None)\n",
    "                dimensions.append(dim_name)\n",
    "\n",
    "            # Create the variable instance\n",
    "            print('creating variable')\n",
    "            nc[cat].createVariable(var, datatype='i8', dimensions=dimensions, fill_value=variable_dict[cat][var]['fill'])\n",
    "\n",
    "            # Create variable metadata\n",
    "            print('creating the metadataverse')\n",
    "            nc[cat][var].long_name = variable_dict[cat][var]['long_name']\n",
    "            nc[cat][var].units = variable_dict[cat][var]['units']\n",
    "            nc[cat][var].scale_factor = variable_dict[cat][var]['scale']\n",
    "\n",
    "            # Create variable array \n",
    "            print('creating variable array')\n",
    "            nc[cat][var][:] = variable_dict[cat][var]['data']\n",
    "            \n",
    "            print(\"\")\n",
    "    return nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/gpfs/gpfs0/project/sdscap-shakeri/nasa/UVA_NASA_2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening new file\n",
      "I_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "create variable array\n",
      "DOLP_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "create variable array\n",
      "Q_over_I_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "create variable array\n",
      "U_over_I_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "create variable array\n",
      "intensity_wavelengths\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "create variable array\n",
      "solar_zenith\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "create variable array\n",
      "sensor_zenith\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "create variable array\n",
      "relative_azimuth\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "create variable array\n",
      "Latitude\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "create variable array\n",
      "Longitude\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "create variable array\n",
      "altitude\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "create variable array\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4 data model, file format HDF5):\n",
       "    dimensions(sizes): I_PARASOL_0(3240), I_PARASOL_1(6480), I_PARASOL_2(16), I_PARASOL_3(9), DOLP_PARASOL_0(3240), DOLP_PARASOL_1(6480), DOLP_PARASOL_2(16), DOLP_PARASOL_3(3), Q_over_I_PARASOL_0(3240), Q_over_I_PARASOL_1(6480), Q_over_I_PARASOL_2(16), Q_over_I_PARASOL_3(3), U_over_I_PARASOL_0(3240), U_over_I_PARASOL_1(6480), U_over_I_PARASOL_2(16), U_over_I_PARASOL_3(3), intensity_wavelengths_0(3240), intensity_wavelengths_1(6480), intensity_wavelengths_2(16), intensity_wavelengths_3(9), solar_zenith_0(3240), solar_zenith_1(6480), solar_zenith_2(16), sensor_zenith_0(3240), sensor_zenith_1(6480), sensor_zenith_2(16), relative_azimuth_0(3240), relative_azimuth_1(6480), relative_azimuth_2(16), Latitude_0(3240), Latitude_1(6480), Longitude_0(3240), Longitude_1(6480), altitude_0(3240), altitude_1(6480)\n",
       "    variables(dimensions): \n",
       "    groups: observation_data, sensor_views_bands, geolocation_data"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_nc(final_dict, 'example.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
