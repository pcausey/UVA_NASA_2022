{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be3d6b7d",
   "metadata": {},
   "source": [
    "# L1C Centering on Latitude\n",
    "This notebook will take an HDF PARASOL file and cast it into L1C format, shedding much of the extraneous data by focusing on the satellite's center of vision. Here we look only at groups of 3 pixels in the center of the satellite's vision. \n",
    "\n",
    "Work needed:\n",
    "* Needs an extension for an option for how many pixels from center it should grab\n",
    "* Extend this to also include an iCARE file acquisition to complete the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c8066e1-f5af-4f51-9658-c2f6fc03bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory and then the filepath within the directory for the file you wish to convert\n",
    "directory = '/project/sdscap-shakeri/nasa/HDF'\n",
    "file_path = 'PARASOL/L1_B-HDF.v1.00/2008/2008_06_01/POLDER3_L1B-BG1-080146M_2008-06-01T00-08-19_V1-00.h5'\n",
    "\n",
    "# Set the filepath you wish to write to along with the name of the file you wish to write\n",
    "write_path = '/gpfs/gpfs0/project/sdscap-shakeri/nasa/UVA_NASA_2021'\n",
    "write_name = 'example_centered.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e645e813-36ab-437f-b21d-2ad317656b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of pixels you want to look at\n",
    "pixels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6e91eab-a472-48b3-92f9-e3d65e16d6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixels: 3\n"
     ]
    }
   ],
   "source": [
    "# Validation on the pixel count, making sure it's an odd number\n",
    "if pixels <= 0 or pixels % 1 != 0:\n",
    "    print(\"Error, enter a valid pixel number, pixels being set to 3\")\n",
    "    pixels = 3\n",
    "elif pixels % 2 == 0 and pixels > 2:\n",
    "    print(\"Error, even number of pixels chosen. Pixels being reset\")\n",
    "    pixels -= 1    \n",
    "    \n",
    "print(\"Pixels:\", pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d4ae23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b25d69-921f-42c3-9ee5-c4d2510a2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory\n",
    "os.chdir(directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7989088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hdf file object in python\n",
    "f = h5py.File(file_path, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c68285",
   "metadata": {},
   "source": [
    "# Precleaning the data\n",
    "We use the I490p field to see which indices we have data for in this hdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af3702f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3240, 6480, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get relevant information and data from the I490P field \n",
    "i490 = f['Data_Directional_Fields']['I490P']\n",
    "i490_fill = i490.attrs['_FillValue']\n",
    "i490_arr = np.array(i490)\n",
    "\n",
    "print(i490_fill)\n",
    "i490_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e72f1",
   "metadata": {},
   "source": [
    "### Cut down extra lat/lons\n",
    "We only want to use columns and rows where actual data exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1bb0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2718\n",
      "5187\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "cols = []\n",
    "for row in range(i490.shape[0]):\n",
    "    inds = np.where(np.abs(i490_arr[row]) != i490_fill)\n",
    "    if (len(inds[0])) > 0:\n",
    "        rows.append(row)\n",
    "        continue\n",
    "\n",
    "print(\"Number of rows:\", len(rows))\n",
    "\n",
    "for col in range(i490.shape[1]):\n",
    "    inds = np.where(np.abs(i490_arr[:,col]) != i490_fill)\n",
    "    if len(inds[0]) > 0:\n",
    "        cols.append(col)\n",
    "        continue\n",
    "                    \n",
    "print(\"Number of columns:\", len(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the shape of the pared down tensor\n",
    "new_shape = (i490_arr[rows])[:,cols].shape\n",
    "shape = i490_arr.shape\n",
    "print(\"Shape:\", np.product(shape))\n",
    "print(\"New Shape:\", np.product(new_shape))\n",
    "print(\"Pct Cut:\", (np.product(new_shape)-np.product(shape))/np.product(shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f796cc4",
   "metadata": {},
   "source": [
    "# Angles, Altitude, & Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35aebdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to store as much information in integer format with scale factors as possible\n",
    "# These variables are set as conversion factors to go between float and a reasonably accurae integer\n",
    "reverse_scale = 1000\n",
    "new_scale = 1/reverse_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f7476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This initializes the dictionary where we'll store all of our information before we cast it to an HDF file. \n",
    "# A dictionary is a natural analog for an HDF file since it also utilizes hierarchical organization\n",
    "final_dict = {}\n",
    "final_dict['geolocation_data'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f6052f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2719, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8157"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get latitude array and corresponding indices\n",
    "# We only want to look at datapoints for which there are legitimate coordinates\n",
    "# Here we'll compile a group of indices that correspond to the satellites center of vision\n",
    "# Width of the vision is set by \"pixels\" above\n",
    "\n",
    "# Geo inds will be the compiled list of centered indices\n",
    "geo_inds = [[],[]]\n",
    "\n",
    "lats = np.array(f['Geolocation_Fields']['Latitude'])\n",
    "lons = np.array(f['Geolocation_Fields']['Longitude'])\n",
    "\n",
    "flag = True\n",
    "\n",
    "# Loop through our latitudes\n",
    "for i in range(lats.shape[0]):\n",
    "    inds = np.where(np.abs(lats[i]) != 99999)[0]\n",
    "\n",
    "    vals = lats[i][inds]\n",
    "\n",
    "    # Ensure that there is only one latitude value for each row\n",
    "    if len(np.unique(vals)) > 1:\n",
    "        print(\"Error\", i)\n",
    "        break\n",
    "    # If there are no values in this row continue\n",
    "    elif len(np.unique(vals)) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        val = np.unique(vals)[0]\n",
    "    \n",
    "    # Find the center of the satellite's view\n",
    "    center_ind = int(np.sum(inds)/len(inds))\n",
    "\n",
    "    # If there aren't any surrounding values continue\n",
    "    # Otherwise append our relevant indices list\n",
    "    if center_ind < 1:\n",
    "        continue\n",
    "    else:\n",
    "        temp_lats = lats[i][center_ind-(pixels-2):center_ind+(pixels-1)] \n",
    "        geo_inds[0].extend([i for u in range(3)])\n",
    "        geo_inds[1].extend([u for u in range(center_ind-1,center_ind+2)])\n",
    "        \n",
    "    if flag:\n",
    "        new_lats = np.array([temp_lats])\n",
    "        flag = False\n",
    "    else:\n",
    "        new_lats = np.append(new_lats, np.array([temp_lats]), axis=0)\n",
    "        \n",
    "# Set the shape of our tensor for later\n",
    "geo_shape = (new_lats.shape)\n",
    "print(geo_shape)\n",
    "len(geo_inds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a263f986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-14aaa9fcb905>:24: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  final_dict['geolocation_data'][tag]['data'] = np.round(temp_arr[geo_inds].reshape(geo_shape)).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude\n",
      "altitude\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-14aaa9fcb905>:27: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  final_dict['geolocation_data'][tag]['data'] = (np.array(f['Geolocation_Fields'][field]))[geo_inds].reshape(geo_shape)\n"
     ]
    }
   ],
   "source": [
    "# Write our geolocation data to the final dictionary\n",
    "# Warnings here are typical, but do not affect data fidelity right now\n",
    "for field in ['Latitude','Longitude','surface_altitude']:\n",
    "    if field == 'surface_altitude':\n",
    "        tag = 'altitude'\n",
    "    else:\n",
    "        tag = field.lower()\n",
    "    print(tag)\n",
    "\n",
    "        \n",
    "    final_dict['geolocation_data'][tag] = {}\n",
    "\n",
    "    final_dict['geolocation_data'][tag]['long_name'] = f['Geolocation_Fields'][field].attrs['long_name']\n",
    "    final_dict['geolocation_data'][tag]['units'] = f['Geolocation_Fields'][field].attrs['units']\n",
    "    \n",
    "    if tag in ['latitude','longitude']:\n",
    "        temp_arr = np.array(f['Geolocation_Fields'][field])\n",
    "        fill = f['Geolocation_Fields'][field].attrs['_FillValue']\n",
    "        fill_inds = np.where(temp_arr == fill)\n",
    "        temp_arr = temp_arr*reverse_scale\n",
    "        temp_arr[fill_inds] = fill\n",
    "        fill = int(fill)\n",
    "        \n",
    "        final_dict['geolocation_data'][tag]['fill'] = fill\n",
    "        final_dict['geolocation_data'][tag]['scale'] = new_scale\n",
    "        final_dict['geolocation_data'][tag]['data'] = np.round(temp_arr[geo_inds].reshape(geo_shape)).astype(int)\n",
    "    else:\n",
    "        final_dict['geolocation_data'][tag]['scale'] = f['Geolocation_Fields'][field].attrs['scale_factor']\n",
    "        final_dict['geolocation_data'][tag]['data'] = (np.array(f['Geolocation_Fields'][field]))[geo_inds].reshape(geo_shape)\n",
    "        final_dict['geolocation_data'][tag]['fill'] = f['Geolocation_Fields'][field].attrs['_FillValue']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e427f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-1d48cb3765a3>:19: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  final_dict['geolocation_data'][tag]['data'] = (np.array(f['Data_Directional_Fields'][field]))[geo_inds].reshape(field_shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solar_zenith (2719, 3, 16)\n",
      "sensor_zenith (2719, 3, 16)\n",
      "relative_azimuth (2719, 3, 16)\n"
     ]
    }
   ],
   "source": [
    "# Write our data directional fields using the aggregated list of indices\n",
    "for field in ['thetas','thetav','phi']:\n",
    "    if field == 'thetas':\n",
    "        tag = 'solar_zenith'\n",
    "    elif field == 'thetav':\n",
    "        tag = 'sensor_zenith'\n",
    "    elif field == 'phi':\n",
    "        tag = 'relative_azimuth'\n",
    "        \n",
    "    # Define the shape of the data\n",
    "    field_shape = list(geo_shape)\n",
    "    field_shape.append(np.array(f['Data_Directional_Fields'][field]).shape[-1])\n",
    "    field_shape = tuple(field_shape)\n",
    "        \n",
    "    final_dict['geolocation_data'][tag] = {}\n",
    "    final_dict['geolocation_data'][tag]['scale'] = f['Data_Directional_Fields'][field].attrs['scale_factor']\n",
    "    final_dict['geolocation_data'][tag]['long_name'] = f['Data_Directional_Fields'][field].attrs['long_name']\n",
    "    final_dict['geolocation_data'][tag]['fill'] = f['Data_Directional_Fields'][field].attrs['_FillValue']\n",
    "    final_dict['geolocation_data'][tag]['units'] = f['Data_Directional_Fields'][field].attrs['units']\n",
    "    final_dict['geolocation_data'][tag]['data'] = (np.array(f['Data_Directional_Fields'][field]))[geo_inds].reshape(field_shape)\n",
    "    print(tag, final_dict['geolocation_data'][tag]['data'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a2eb8",
   "metadata": {},
   "source": [
    "# Generate I, Q, & U fields\n",
    "Use the indices that we've aggreagated to capture the measurement fields that we require"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93a3e4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_np\n",
      "tag: I\n",
      "I1020NP, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-8d4c14384ad1>:34: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  arrays.append(np.array(f['Data_Directional_Fields'][field])[geo_inds].reshape(field_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I443NP, I490P, I565NP, I670P, I763NP, I765NP, I865P, I910NP, (2719, 3, 16, 9)\n",
      "I_p\n",
      "tag: I\n",
      "I490P, I670P, I865P, (2719, 3, 16, 3)\n",
      "Q\n",
      "tag: Q\n",
      "Q490P, Q670P, Q865P, (2719, 3, 16, 3)\n",
      "U\n",
      "tag: U\n",
      "U490P, U670P, U865P, (2719, 3, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "# Set an interim dictionary which will hold all of our raw I, Q, & U data and metadata before we transform it and write it to the final dictionary and HDF\n",
    "measurement_dict = {}\n",
    "\n",
    "# Loop through each of these fields\n",
    "for cat in ['I_np','I_p','Q','U']:\n",
    "    print(cat)\n",
    "    \n",
    "    # Look for either polarized or non-polarized fields\n",
    "    if cat == 'I_np':\n",
    "        tag = cat.replace('_np','')\n",
    "        fields = ([field for field in list(f['Data_Directional_Fields'].keys()) if (tag in field)])\n",
    "    else:\n",
    "        tag = cat.replace('_p','')\n",
    "        fields = ([field for field in list(f['Data_Directional_Fields'].keys()) if (tag in field) and ('NP' not in field)])\n",
    "\n",
    "    print(\"tag:\", tag)\n",
    "    fields.sort()\n",
    "    \n",
    "    # Define the shape of the data\n",
    "    field_shape = list(geo_shape)\n",
    "    field_shape.append(np.array(f['Data_Directional_Fields'][field]).shape[-1])\n",
    "    field_shape = tuple(field_shape)    \n",
    "    \n",
    "    # Set some empty variables here\n",
    "    arrays = []\n",
    "    scales = []\n",
    "    long_names = []\n",
    "    fills = []\n",
    "    units = []\n",
    "    \n",
    "    # Loop through each of the relvant fields and look for the information that we require\n",
    "    for field in fields:\n",
    "            \n",
    "        print(field, end=\", \")\n",
    "        \n",
    "        scales.append(f['Data_Directional_Fields'][field].attrs['scale_factor'])\n",
    "        long_names.append(f['Data_Directional_Fields'][field].attrs['long_name'])\n",
    "        fills.append(f['Data_Directional_Fields'][field].attrs['_FillValue'])\n",
    "        units.append(f['Data_Directional_Fields'][field].attrs['units'])\n",
    "        \n",
    "        arrays.append(np.array(f['Data_Directional_Fields'][field])[geo_inds].reshape(field_shape))\n",
    "\n",
    "    if len(np.unique(scales)) == 1:\n",
    "        scales = scales[0]\n",
    "    if len(np.unique(fills)) == 1:\n",
    "        fills = fills[0]\n",
    "    if len(np.unique(units)) == 1:\n",
    "        units = units[0]\n",
    "    \n",
    "    # Add our fields to the measurement dictionary\n",
    "    measurement_dict[cat] = {}\n",
    "    measurement_dict[cat]['fields'] = fields\n",
    "    measurement_dict[cat]['scale'] = scales\n",
    "    measurement_dict[cat]['long_name'] = long_names\n",
    "    measurement_dict[cat]['fill'] = fills\n",
    "    measurement_dict[cat]['units'] = units\n",
    "    measurement_dict[cat]['data'] = np.stack(arrays,axis=3)\n",
    "    print(measurement_dict[cat]['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a81ede2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2719, 3, 16, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurement_dict['I_np']['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab34d1d",
   "metadata": {},
   "source": [
    "# Create Observation Data field in the Final Dictionary and Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88199a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the empty field within the final dictionary\n",
    "final_dict['observation_data'] = {}\n",
    "\n",
    "# Take the non-polarized intensity readings and move them directly to the final dictionary\n",
    "# No transformations needed here\n",
    "final_dict['observation_data']['I_PARASOL'] = copy.deepcopy(measurement_dict['I_np'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b4474a",
   "metadata": {},
   "source": [
    "## Wavelengths\n",
    "Here we set the map that tells us which indices correspond to each wavelength and polarization state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1897da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarization_wavelengths\n",
      "(16, 3)\n",
      "\n",
      "intensity_wavelengths\n",
      "(16, 9)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the empty field sensor view bands in our final dictionary\n",
    "final_dict['sensor_views_bands'] = {}\n",
    "\n",
    "# Loop through polarized and non-polarized settings\n",
    "for i in [True, False]:\n",
    "    if i:\n",
    "        tag = 'I_p'\n",
    "        field_name = 'polarization_wavelengths'\n",
    "        lambdas = [int(field.replace('I','').replace('P','')) for field in measurement_dict[tag]['fields']]\n",
    "\n",
    "    else:\n",
    "        tag = 'I_np'\n",
    "        field_name = 'intensity_wavelengths'\n",
    "        lambdas = [int(field.replace('I','').replace('NP','').replace('P','')) for field in measurement_dict[tag]['fields']]\n",
    "\n",
    "\n",
    "    shape = measurement_dict[tag]['data'].shape\n",
    "    new_shape = []\n",
    "    lambda_arrs = []\n",
    "    \n",
    "    print(field_name)\n",
    "    \n",
    "    for lam in lambdas:  \n",
    "        lambda_arrs.append(np.full(16,lam))\n",
    "\n",
    "    full_lambdas_arr = np.stack(lambda_arrs,axis=1)\n",
    "    print(full_lambdas_arr.shape)\n",
    "\n",
    "    \n",
    "    final_dict['sensor_views_bands'][field_name] = {}\n",
    "    final_dict['sensor_views_bands'][field_name]['scale'] = 1\n",
    "    final_dict['sensor_views_bands'][field_name]['long_name'] = 'field_name'\n",
    "    final_dict['sensor_views_bands'][field_name]['fill'] = 32767\n",
    "    final_dict['sensor_views_bands'][field_name]['units'] = 'tbd'\n",
    "    final_dict['sensor_views_bands'][field_name]['data'] = full_lambdas_arr\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da555bf8",
   "metadata": {},
   "source": [
    "## DOLP\n",
    "Here we'll calculate the degree of linear polarization tensors \n",
    "* DOLP = sqrt(Q^2 + U^2)/I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fbe6002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32767"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = measurement_dict['Q']['scale']\n",
    "fill = measurement_dict['Q']['fill']\n",
    "print(\"Scale:\", scale)\n",
    "print(\"Fill:\", fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d724ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors for each of our I, Q, and U stokes datasets\n",
    "for key in measurement_dict.keys():\n",
    "    if key == 'I_p':\n",
    "        I_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        I_arr[np.abs(I_arr) == fill] = 1\n",
    "    \n",
    "    elif key == 'Q':\n",
    "        Q_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        Q_arr[np.abs(Q_arr) == fill] = 1\n",
    "        \n",
    "    elif key == 'U':\n",
    "        U_arr = copy.deepcopy(measurement_dict[key]['data']) * scale\n",
    "        U_arr[np.abs(U_arr) == fill] = 1\n",
    "        \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40e644c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-bca893dafdb9>:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  DOLP_arr_unfltrd = np.divide(np.sqrt(np.add(np.square(Q_arr), np.square(U_arr))), I_arr)*reverse_scale\n"
     ]
    }
   ],
   "source": [
    "# Create the unfiltered degreee of linear polarization (DOLP) tensor\n",
    "DOLP_arr_unfltrd = np.divide(np.sqrt(np.add(np.square(Q_arr), np.square(U_arr))), I_arr)*reverse_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5926409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DOLP data to the final dictionary\n",
    "final_dict['observation_data']['DOLP_PARASOL'] = {}\n",
    "final_dict['observation_data']['DOLP_PARASOL']['scale'] = new_scale\n",
    "final_dict['observation_data']['DOLP_PARASOL']['long_name'] = 'Degree of linear polarization'\n",
    "final_dict['observation_data']['DOLP_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['DOLP_PARASOL']['units'] = 'None'\n",
    "final_dict['observation_data']['DOLP_PARASOL']['data'] = np.round(DOLP_arr_unfltrd).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81e310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "829ca41e",
   "metadata": {},
   "source": [
    "## Q over I, U over I\n",
    "\n",
    "Acquire and write our Q/I and U/I datasets to the final_dictionary along with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e6508a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Q over I\n",
      "Processing U over I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-63afa7411eca>:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  Q_over_I = np.divide(Q_arr, I_arr)*reverse_scale\n",
      "<ipython-input-29-63afa7411eca>:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  U_over_I = np.divide(U_arr, I_arr)*reverse_scale\n"
     ]
    }
   ],
   "source": [
    "Q_over_I = np.divide(Q_arr, I_arr)*reverse_scale\n",
    "U_over_I = np.divide(U_arr, I_arr)*reverse_scale\n",
    "\n",
    "Q_over_I[np.where((measurement_dict['I_p']['data'] == fill) | \n",
    "                          (measurement_dict['Q']['data'] == fill) | \n",
    "                          (measurement_dict['U']['data'] == fill))] = fill\n",
    "\n",
    "U_over_I[np.where((measurement_dict['I_p']['data'] == fill) | \n",
    "                          (measurement_dict['Q']['data'] == fill) | \n",
    "                          (measurement_dict['U']['data'] == fill))] = fill\n",
    "\n",
    "print(\"Processing Q over I\")\n",
    "final_dict['observation_data']['Q_over_I_PARASOL'] = {}\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['scale'] = new_scale\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['long_name'] = 'Q over I'\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['units'] = 'None'\n",
    "final_dict['observation_data']['Q_over_I_PARASOL']['data'] = np.round(Q_over_I).astype(int)\n",
    "\n",
    "print(\"Processing U over I\")\n",
    "final_dict['observation_data']['U_over_I_PARASOL'] = {}\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['scale'] = new_scale\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['long_name'] = 'U over I'\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['fill'] = fill\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['units'] = 'None'\n",
    "final_dict['observation_data']['U_over_I_PARASOL']['data'] = np.round(U_over_I).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4f7b0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geolocation_data latitude int64\n",
      "geolocation_data longitude int64\n",
      "geolocation_data altitude int16\n",
      "geolocation_data solar_zenith uint16\n",
      "geolocation_data sensor_zenith uint16\n",
      "geolocation_data relative_azimuth uint16\n",
      "observation_data I_PARASOL int16\n",
      "observation_data DOLP_PARASOL int64\n",
      "observation_data Q_over_I_PARASOL int64\n",
      "observation_data U_over_I_PARASOL int64\n",
      "sensor_views_bands polarization_wavelengths int64\n",
      "sensor_views_bands intensity_wavelengths int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure that each of our fields is cast as an int to save space in the file\n",
    "for cat in final_dict.keys():\n",
    "    for variable in final_dict[cat]:\n",
    "        print(cat, variable, (final_dict[cat][variable]['data']).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eab92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nc(variable_dict, filename, verbose=False):\n",
    "    \"\"\"\n",
    "    Writes a .NC file, a hierarchical data format used in L1C, with our newly formatted and aggregated data\n",
    "    variable_dict = file_dict in the rest of the document\n",
    "    When verbose = True it will output a running log of complete tasks\n",
    "    \"\"\"\n",
    "    \n",
    "    nc = Dataset(filename, mode='w', format='NETCDF4')\n",
    "\n",
    "    for cat in variable_dict.keys():\n",
    "        if verbose:\n",
    "            print(\"Starting:\", cat)\n",
    "        \n",
    "        # Create the category group to store the variables\n",
    "        nc.createGroup(cat)\n",
    "\n",
    "        for var in variable_dict[cat].keys():\n",
    "            if verbose:\n",
    "                print(var)\n",
    "\n",
    "            shape = final_dict[cat][var]['data'].shape\n",
    "            \n",
    "            # Fill the dimension with variables\n",
    "            dimensions = []\n",
    "            for i in range(len(shape)):  \n",
    "                dim_name = f'{var}_{i}'\n",
    "                nc.createDimension(dim_name, size=shape[i])\n",
    "                dimensions.append(dim_name)\n",
    "\n",
    "            # Create the variable instance\n",
    "            if verbose:\n",
    "                print('creating variable')\n",
    "            nc[cat].createVariable(var, datatype='i8', dimensions=dimensions, fill_value=variable_dict[cat][var]['fill'])\n",
    "\n",
    "            # Create variable metadata\n",
    "            if verbose:\n",
    "                print('creating the metadataverse')\n",
    "            nc[cat][var].long_name = variable_dict[cat][var]['long_name']\n",
    "            nc[cat][var].units = variable_dict[cat][var]['units']\n",
    "            nc[cat][var].scale_factor = variable_dict[cat][var]['scale']\n",
    "\n",
    "            # Create variable array \n",
    "            if verbose:\n",
    "                print('creating variable array')\n",
    "            nc[cat][var][:] = variable_dict[cat][var]['data']\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"\")\n",
    "            \n",
    "    nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc692adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: geolocation_data\n",
      "latitude\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "longitude\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "altitude\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "solar_zenith\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "sensor_zenith\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "relative_azimuth\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "Starting: observation_data\n",
      "I_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "DOLP_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "Q_over_I_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "U_over_I_PARASOL\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "Starting: sensor_views_bands\n",
      "polarization_wavelengths\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n",
      "intensity_wavelengths\n",
      "creating variable\n",
      "creating the metadataverse\n",
      "creating variable array\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change the directory to where you want to write the file to and convert the file in question \n",
    "os.chdir(write_path)\n",
    "write_nc(final_dict, write_name, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
